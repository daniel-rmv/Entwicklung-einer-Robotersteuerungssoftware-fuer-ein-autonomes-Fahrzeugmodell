Roboter-Projekt: 4WD Mecanum-Chassis + Greifarm (ArmPi Pro) + Raspberry Pi 5 + LiDAR + OpenCV

Willkommen in meinem Roboter-Projekt!
Dieses Repository enthÃ¤lt den Code, die Dokumentation und die Konfigurationen fÃ¼r einen autonomen Roboter, der auf einem 4WD Mecanum-Rad-Chassis basiert. Ausgestattet mit einem ArmPi Pro-Greifarm, einem Orbbec Oradar MS200 LiDAR und einer Kamera, nutzt der Roboter C++, OpenCV und den LiDAR Sensor, um Hindernisse zu vermeiden, Objekte zu erkennen und autonom zu navigieren.

Inhaltsverzeichnis
	1.	Ãœberblick
	2.	Funktionen & Features
	3.	System-Architektur
	4.	Installation & Vorbereitung
	5.	Projektstruktur
	6.	Build & Run
	7.	Verwendung (Use Cases)
	8.	Weiterentwicklung
	9.	Lizenz & Kontakt

1. Ãœberblick

Das Ziel dieses Projekts ist es, einen vielseitigen Roboter zu entwickeln, der:
	â€¢	Autonom navigieren kann.
	â€¢	Hindernisse erkennt und vermeidet (LiDAR).
	â€¢	Objekte erkennt (OpenCV) und diese mit einem Greifarm prÃ¤zise manipuliert.

2. Funktionen & Features

	â€¢	Mecanum-Wheel-Fahrgestell: ErmÃ¶glicht Bewegungen in alle Richtungen.
	â€¢	ArmPi Pro-Greifarm: PrÃ¤zise Objektmanipulation dank Servo-Motoren.
	â€¢	Orbbec Oradar MS200 LiDAR: Hinderniserkennung, Abstandsmessung, Erkennungs der Position im GelÃ¤nde und anpassung der einzelnen Motoren, um unprÃ¤zise Algorithmusberechnungen auszugleichen.
	â€¢	OpenCV-basierte Objekterkennung: Analyse von Farben, Formen und GrÃ¶ssen dank KI.
	â€¢	Modularer C++-Code: Sauber strukturierte Klassen fÃ¼r Navigation, Vision und Steuerung.

3. System-Architektur

Ein vereinfachtes UML-Diagramm beschreibt die Hauptklassen:
	â€¢	RobotSystem: Koordiniert alle Subsysteme.
	â€¢	NavigationSystem: Nutzt LiDAR-Daten fÃ¼r Pfadplanung, Hindernisvermeidung und Kommunikation mit MotorController.
	â€¢	VisionSystem: Erkennt Objekte Ã¼ber OpenCV.
	â€¢	ArmController: Steuert den ArmPi Pro-Greifarm.
	â€¢	MotorController: Steuerung der Mecanum-Wheels.
	â€¢	Logger: Schreibt Systemmeldungen und Fehler.

4. Installation & Vorbereitung

Voraussetzungen:
	â€¢	Hardware: Raspberry Pi 4, ArmPi Pro-Greifarm, LiDAR (Orbbec Oradar MS200).
	â€¢	Software:
	â€¢	CMake: FÃ¼r den Build-Prozess.
	â€¢	OpenCV: Installation via sudo apt-get install libopencv-dev.
	â€¢	LiDAR-Treiber und SDK (abhÃ¤ngig vom Modell).
    â€¢   WiringPi Bibliothek

5. Setup:
	a)	Repository klonen:

git clone https://gitlab.com/danielrmv/Entwicklung-einer-Robotersteuerungssoftware-fuer-ein-autonomes-Fahrzeugmodell
    oder
    https://github.com/daniel-rmv/Entwicklung-einer-Robotersteuerungssoftware-fuer-ein-autonomes-Fahrzeugmodell

cd Implementation/RobotControlSystem


	b)	Build-Ordner erstellen und kompilieren:

mkdir build && cd build
cmake ..
make


	c)	Programm ausfÃ¼hren:

sudo ./RobotControlSystem
oder
./RobotControlSystem

6. Projektstruktur

RobotControlSystem/
â”œâ”€â”€ CMakeLists.txt          # Build-Konfiguration
â”œâ”€â”€ src/                    # Quellcode
â”‚   â”œâ”€â”€ main.cpp            # Einstiegspunkt
â”‚   â”œâ”€â”€ RobotSystem.cpp
â”‚   â”œâ”€â”€ NavigationSystem.cpp
â”‚   â”œâ”€â”€ VisionSystem.cpp
â”‚   â”œâ”€â”€ ArmController.cpp
â”‚   â”œâ”€â”€ MotorController.cpp
â”‚   â”œâ”€â”€ Motor.cpp
â”‚   â”œâ”€â”€ LidarSensor.ccp
â”‚   â”œâ”€â”€ ServoMotor.cpp
â”‚   â”œâ”€â”€ Motor.cpp
â”‚   â”œâ”€â”€ Gripper.cpp
â”‚   â”œâ”€â”€ Camera.cpp
â”‚   â””â”€â”€ Logger.cpp
â”œâ”€â”€ include/                # Header-Dateien
â”œâ”€â”€ resources/              # Trainingsdaten, Bilder
â”œâ”€â”€ docs/                   # Dokumentationen, UML-Diagramme
â””â”€â”€ README.md               # Dieses Dokument

7. Build & Run

Build:
	1.	Kompiliere das Projekt mit CMake und make.
	2.	Stelle sicher, dass alle AbhÃ¤ngigkeiten installiert sind.

AusfÃ¼hren:
	1.	Starte das Programm mit ./RobotControlSystem oder sudo ./RobotControlSystem.
	2.	Konfiguriere ggf. Ports und Sensoreinstellungen (z. B. config.yaml).

8. Verwendung (Use Cases)

1. Navigation & Hindernisvermeidung
	â€¢	Ziel: Der Roboter navigiert sicher zu vordefinierten Wegpunkten.
	â€¢	Ablauf:
	1.	NavigationSystem::navigate(myPath)
	2.	LiDAR erkennt Hindernisse.
	3.	Der Roboter weicht aus oder stoppt.

2. Objekterkennung & Greifen
	â€¢	Ziel: Der Roboter erkennt Objekte (z. B. â€œroter WÃ¼rfelâ€) und greift diese.
	â€¢	Ablauf:
	1.	VisionSystem::detectObjects()
	2.	ArmController::pickObject()
	3.	Objekt wird transportiert und abgelegt.

Weiterentwicklung
	â€¢	BenutzeroberflÃ¤che: GUI zur Echtzeit-Ãœberwachung und Steuerung.

Lizenz & Kontakt
	â€¢	Lizenz: MIT
	â€¢	Kontakt:
	â€¢	GitLab: danielrmv
    â€¢   GitHub: danielrmv   
	â€¢	E-Mail: info@danielwuermli.com

Dieses Projekt steht unter der [MIT-Lizenz](./LICENSE). Weitere Informationen findest du in der LICENSE-Datei.

Feedback und VerbesserungsvorschlÃ¤ge sind jederzeit willkommen! ğŸ‰
